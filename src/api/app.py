import os
import httpx # requests ëŒ€ì‹  ì‚¬ìš©í•˜ëŠ” ë¹„ë™ê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬ (pip install httpx)
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware # CORS ë¯¸ë“¤ì›¨ì–´
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# --- LangChain ê´€ë ¨ ---
from langchain_community.vectorstores import FAISS
# from langchain_community.embeddings import HuggingFaceEmbeddings # ë¡œì»¬ ëª¨ë¸ ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ
from langchain_openai import ChatOpenAI, OpenAIEmbeddings # OpenAI ì‚¬ìš© ì‹œ
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

# --- .env ë¡œë“œ ---
load_dotenv()

# --- 1. ì„¤ì • ---
# â˜… ì¤‘ìš”: DB ë§Œë“¤ ë•Œ ì“´ ëª¨ë¸ê³¼ ë˜‘ê°™ì€ ê±¸ ì¨ì•¼ í•©ë‹ˆë‹¤!
# DB_FAISS_PATH = "faiss_index"         # ë¡œì»¬ ëª¨ë¸(KURE)ë¡œ ë§Œë“  DB ê²½ë¡œ
DB_FAISS_PATH = "faiss_index_openai"  # OpenAIë¡œ ë§Œë“  DB ê²½ë¡œ
USE_OPENAI_EMBEDDING = True           # Trueë©´ OpenAI, Falseë©´ KURE(ë¡œì»¬)

# ì „ì—­ ë³€ìˆ˜ (DB, Embeddings, LLM)
resources = {}

# --- 2. Lifespan (ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰) ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    # [ì‹œì‘ ì‹œ ì‹¤í–‰]
    print("ğŸš€ FastAPI ì„œë²„ ì‹œì‘ ì¤‘...")
    
    # 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    try:
        if USE_OPENAI_EMBEDDING:
            print("Settings: OpenAI Embeddings (text-embedding-3-small)")
            resources['embeddings'] = OpenAIEmbeddings(model="text-embedding-3-small")
        else:
            print("Settings: HuggingFace Embeddings (nlpai-lab/KURE-v1)")
            # resources['embeddings'] = HuggingFaceEmbeddings(
            #     model_name="nlpai-lab/KURE-v1",
            #     model_kwargs={'device': 'cpu'}
            # )
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

    # 2. Vector DB ë¡œë“œ
    if os.path.exists(DB_FAISS_PATH):
        try:
            print(f"ğŸ“‚ Vector DB ë¡œë“œ ì¤‘: {DB_FAISS_PATH}")
            resources['db'] = FAISS.load_local(
                DB_FAISS_PATH, 
                resources['embeddings'],
                allow_dangerous_deserialization=True
            )
            print("âœ… Vector DB ë¡œë“œ ì™„ë£Œ.")
        except Exception as e:
            print(f"âŒ Vector DB ë¡œë“œ ì—ëŸ¬: {e}")
            resources['db'] = None
    else:
        print(f"âš ï¸ ê²½ê³ : '{DB_FAISS_PATH}' ê²½ë¡œì— DBê°€ ì—†ìŠµë‹ˆë‹¤.")
        resources['db'] = None

    # 3. LLM ì´ˆê¸°í™”
    resources['llm'] = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    yield # ì—¬ê¸°ì„œë¶€í„° ì„œë²„ ê°€ë™

    # [ì¢…ë£Œ ì‹œ ì‹¤í–‰]
    print("ğŸ‘‹ ì„œë²„ ì¢…ë£Œ. ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.")
    resources.clear()

# --- 3. FastAPI ì•± ìƒì„± ---
app = FastAPI(
    title="FactCheck RAG API",
    description="ë‰´ìŠ¤ ê¸°ì‚¬ íŒ©íŠ¸ì²´í¬ ë° ìœ ì‚¬ë„ ê²€ìƒ‰ API",
    lifespan=lifespan
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ í•„ìˆ˜)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # ë³´ì•ˆìƒ ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” ["http://localhost:3000"] ë“±ìœ¼ë¡œ ì œí•œ ê¶Œì¥
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 4. ë°ì´í„° ëª¨ë¸ ---
# [ì‚­ì œ/ì£¼ì„] GET ë°©ì‹ì—ì„œëŠ” Request Bodyìš© ëª¨ë¸ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
# class FactCheckRequest(BaseModel):
#     url: str 

class FactCheckResponse(BaseModel):
    original_claims: List[Dict[str, str]]
    related_factchecks: List[Dict[str, Any]]

class SearchResult(BaseModel):
    content: str
    metadata: Dict[str, Any]
    score: float

class SearchResponse(BaseModel):
    query: str
    results: List[SearchResult]

class EmbedResponse(BaseModel):
    text: str
    vector: List[float]

# --- 5. ë¹„ë™ê¸° í—¬í¼ í•¨ìˆ˜ ---

async def crawl_naver_news_async(url: str) -> str:
    """
    httpxë¥¼ ì‚¬ìš©í•œ ì§„ì •í•œ ë¹„ë™ê¸° í¬ë¡¤ë§
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        async with httpx.AsyncClient() as client:
            # follow_redirects=True: ë‹¨ì¶• URL ë“± ë¦¬ë‹¤ì´ë ‰íŠ¸ ìë™ ì²˜ë¦¬
            response = await client.get(url, headers=headers, follow_redirects=True, timeout=10.0)
            response.raise_for_status()
            html = response.text
            
            soup = BeautifulSoup(html, 'html.parser')
            # ë³¸ë¬¸ ì¶”ì¶œ ë¡œì§
            content = soup.select_one('#dic_area')
            if not content:
                content = soup.select_one('#articeBody')
            
            if content:
                # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
                for tag in content(['script', 'style', 'iframe', 'button']):
                    tag.decompose()
                return content.get_text(strip=True)
            return ""
    except Exception as e:
        print(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return ""

async def extract_claims_async(text: str):
    """
    ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì£¼ì¥ ì¶”ì¶œ (LLM)
    """
    if not text or len(text) < 50:
        return []

    system_prompt = """ë‹¹ì‹ ì€ íŒ©íŠ¸ì²´í¬ë¥¼ ìœ„í•œ ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ 'ê²€ì¦ ê°€ëŠ¥í•œ í•µì‹¬ ì£¼ì¥(Claim)'ì„ 3ê°œ ì¶”ì¶œí•˜ì„¸ìš”.

[ì¶œë ¥ í˜•ì‹ - JSON Only]
[
  {
    "claim": "ì£¼ì¥ ë‚´ìš© (í•œ ë¬¸ì¥)",
    "type": "Fact" ë˜ëŠ” "Opinion",
    "query": "ê²€ìƒ‰ìš© ì¿¼ë¦¬ (í•µì‹¬ í‚¤ì›Œë“œ ìœ„ì£¼)"
  }
]
"""
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{text}")
    ])
    
    # ë¦¬ì†ŒìŠ¤ì—ì„œ LLM ê°€ì ¸ì˜¤ê¸°
    llm = resources.get('llm')
    if not llm: return []

    chain = prompt | llm | JsonOutputParser()
    
    try:
        # ë³¸ë¬¸ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ë³´ëƒ„ (í† í° ì ˆì•½)
        return await chain.ainvoke({"text": text[:3500]})
    except Exception as e:
        print(f"í´ë ˆì„ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []

# --- 6. ì—”ë“œí¬ì¸íŠ¸ ---

@app.get("/check-facts", response_model=FactCheckResponse, summary="URL ê¸°ë°˜ íŒ©íŠ¸ì²´í¬ (GET)")
async def check_facts_by_url(url: str):
    """
    [GET] /check-facts?url=https://n.news.naver.com/... í˜•íƒœë¡œ ìš”ì²­
    """
    db = resources.get('db')
    if not db:
        raise HTTPException(status_code=503, detail="Vector DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # 1. í¬ë¡¤ë§
    article_text = await crawl_naver_news_async(url)
    if not article_text:
        raise HTTPException(status_code=400, detail="ê¸°ì‚¬ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 2. í´ë ˆì„ ì¶”ì¶œ
    claims = await extract_claims_async(article_text)
    if not claims:
        # ì£¼ì¥ì´ ì•ˆ ë½‘í˜”ì„ ê²½ìš° ë¹ˆ ê²°ê³¼ ë°˜í™˜ ëŒ€ì‹  ì—ëŸ¬ ì²˜ë¦¬ ì„ íƒ ê°€ëŠ¥
        return FactCheckResponse(original_claims=[], related_factchecks=[])

    # 3. DB ê²€ìƒ‰
    related_results = []
    
    for claim in claims:
        query = claim.get('query')
        if not query: continue

        # k=2, ìœ ì‚¬ë„ ê²€ìƒ‰
        docs_with_scores = db.similarity_search_with_score(query, k=2)
        
        search_hits = []
        for doc, score in docs_with_scores:
            # ê±°ë¦¬(Distance) ê¸°ë°˜ í•„í„°ë§
            # OpenAI Embeddings + FAISS(L2)ì˜ ê²½ìš°:
            # 0.0 = ì™„ì „ ì¼ì¹˜, 1.0 ì´ìƒ = ê´€ë ¨ ì—†ìŒ
            # ë³´í†µ 0.5 ~ 0.7 ì‚¬ì´ë¥¼ ì„ê³„ê°’ìœ¼ë¡œ ì¡ìŒ (ë°ì´í„°ì— ë”°ë¼ ë‹¤ë¦„)
            
            # ë„ˆë¬´ ë¨¼ ê²°ê³¼ ì œì™¸ (ì„ê³„ê°’ ì¡°ì • í•„ìš”)
            if score > 1.2: 
                continue

            search_hits.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "score": float(score)
            })
        
        related_results.append({
            "claim": claim.get('claim'),
            "query": query,
            "related_facts": search_hits
        })

    return FactCheckResponse(
        original_claims=claims,
        related_factchecks=related_results
    )

@app.get("/search", response_model=SearchResponse, summary="ë‹¨ìˆœ ê²€ìƒ‰")
def search_latent_space(q: str, k: int = 3):
    db = resources.get('db')
    if not db:
        raise HTTPException(status_code=503, detail="Vector DB Not Ready")
    
    docs_with_scores = db.similarity_search_with_score(q, k=k)
    
    results_list = []
    for doc, score in docs_with_scores:
        results_list.append(SearchResult(
            content=doc.page_content,
            metadata=doc.metadata,
            score=score
        ))
    
    return SearchResponse(query=q, results=results_list)

@app.get("/", summary="Health Check")
def read_root():
    return {"status": "OK", "model": "OpenAI" if USE_OPENAI_EMBEDDING else "Local"}